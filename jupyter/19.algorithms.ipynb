{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part XIX: Algorithms <a id=\"19-algorithms\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Time Complexity and Big O Notation <a id=\"time-complexity-and-big-o-notation\"></a>\n",
    "\n",
    "_Time complexity_ and _Big O_ notation are foundational concepts in computer science, particularly in the analysis of algorithms. They are used to describe the performance of algorithms and the amount of time they take to run as a function of the size of their input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Complexity <a id=\"time-complexity\"></a>\n",
    "\n",
    "_Time complexity_ is a measure of the amount of computational time that an algorithm takes to complete as a function of the length of the input. It gives us an idea of the growth rate of the runtime of an algorithm as the size of input data increases. Time complexity is important because it helps us to predict the scalability of an algorithm and to determine whether it is practical for large datasets.\n",
    "\n",
    "There are several types of time complexity measures, including:\n",
    "\n",
    "- **Worst-case time complexity (Big O notation)**: The maximum amount of time an algorithm could take to complete, regardless of the input size.\n",
    "- **Average-case time complexity (ùõÄ omega notation)**: The expected amount of time an algorithm will take to complete, over all possible inputs of a given size.\n",
    "- **Best-case time complexity (ùöØ theta notation)**: The minimum amount of time an algorithm could take to complete, which usually occurs under ideal conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big O Notation <a id=\"big-o-notation\"></a>\n",
    "\n",
    "_Big O_ notation is a mathematical notation used to describe the upper bound of the time complexity of an algorithm. It expresses the worst-case scenario of an algorithm's growth rate, allowing us to compare the efficiency of different algorithms regardless of hardware or software differences. Big O notation focuses on the main factor that affects the growth rate, ignoring constants and smaller terms, which become negligible as the input size grows.\n",
    "\n",
    "Here are some common Big O notations and their meanings:\n",
    "\n",
    "- **O(1)**: Constant time - The execution time of the algorithm does not change with the size of the input data set.\n",
    "- **O(log n)**: Logarithmic time - The execution time of the algorithm increases logarithmically as the input data set size increases.\n",
    "- **O(n)**: Linear time - The execution time increases linearly with the increase in input data set size.\n",
    "- **O(n log n)**: Linearithmic time - The execution time increases linearly and logarithmically with the increase in input data set size. Many efficient sorting algorithms have this time complexity.\n",
    "- **O(n^2)**: Quadratic time - The execution time increases quadratically with the increase in input data set size. This is common in algorithms that involve nested iterations over the data set.\n",
    "- **O(2^n)**: Exponential time - The execution time doubles with each addition to the input data set size. This is often seen in algorithms that generate all subsets of a set.\n",
    "- **O(n!)**: Factorial time - The execution time grows factorially with the increase in input data set size. This is typical in algorithms that generate all permutations of a set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Data Structure Time Complexities <a id=\"common-data-structure-time-complexities\"></a>\n",
    "\n",
    "Here are the time complexities for common data structures:\n",
    "\n",
    "| Data Structure         | Access    | Search    | Insertion | Deletion  | Remarks                      |\n",
    "|------------------------|-----------|-----------|-----------|-----------|------------------------------|\n",
    "| Array (Dynamic)        | O(1)      | O(n)      | O(n)      | O(n)      | Worst case for insertion/deletion due to resizing and copying. |\n",
    "| Array (Fixed Size)     | O(1)      | O(n)      | N/A       | N/A       | Size is fixed; cannot insert or delete. |\n",
    "| Singly Linked List     | O(n)      | O(n)      | O(1)      | O(1)      | Assuming insertion/deletion at the head. |\n",
    "| Doubly Linked List     | O(n)      | O(n)      | O(1)      | O(1)      | Assuming insertion/deletion at the head/tail. |\n",
    "| Stack                  | O(n)      | O(n)      | O(1)      | O(1)      | Access is O(n) since you need to pop n-1 elements to access the nth. |\n",
    "| Queue                  | O(n)      | O(n)      | O(1)      | O(1)      | Enqueue is O(1), dequeue is O(1); accessing arbitrary elements is O(n). |\n",
    "| Deque (Double-Ended Queue) | O(n)   | O(n)      | O(1)      | O(1)      | Insertion and deletion are O(1) at both ends. |\n",
    "| Hash Table (Unsorted)  | N/A       | O(1)      | O(1)      | O(1)      | Average case; worst-case is O(n) if a collision occurs. |\n",
    "| Binary Search Tree     | O(log n)  | O(log n)  | O(log n)  | O(log n)  | Average case for balanced tree; worst-case is O(n) if unbalanced. |\n",
    "| Balanced Tree (AVL, Red-Black Tree) | O(log n) | O(log n) | O(log n)  | O(log n)  | Maintains balance to ensure O(log n) operations. |\n",
    "| Heap (Binary)          | O(1)      | O(n)      | O(log n)  | O(log n)  | Min/Max value is O(1); finding arbitrary values is O(n). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sorting Algorithms <a id=\"sorting-algorithms\"></a>\n",
    "\n",
    "_Sorting algorithms_ are used to rearrange a list of elements into a particular order, such as numerical, lexicographical, or some other order. Sorting is a fundamental operation in computer science and is used in a wide variety of applications, including searching, data analysis, and database operations.\n",
    "\n",
    "There are many different sorting algorithms, each with its own advantages and disadvantages. The choice of sorting algorithm depends on the size of the data set, the nature of the data, and the available resources. Here are some common sorting algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bubble Sort <a id=\"bubble-sort\"></a>\n",
    "\n",
    "_Bubble Sort_ is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted. The algorithm is named for the way smaller elements \"bubble\" to the top of the list (beginning of the list) because, during each pass, the largest unsorted element bubbles up to its correct position.\n",
    "\n",
    "- **Time Complexity**:\n",
    "  - **Best Case**: _O(n)_ when the array is already sorted, and the algorithm makes a pass to check.\n",
    "  - **Average Case**: _O(n^2)_ for unsorted or partially sorted arrays.\n",
    "  - **Worst Case**: _O(n^2)_ when the array is sorted in reverse order.\n",
    "- **Space Complexity**: _O(1)_ since it only uses a constant amount of extra space for swapping.\n",
    "\n",
    "_How Bubble Sort Works:_\n",
    "\n",
    "1. **Starting from the first index**, compare the current element with the next element.\n",
    "2. **Swap** if the current element is greater than the next element.\n",
    "3. **Move to the next element** and repeat the process until the end of the array.\n",
    "4. After each pass, the largest element among the unsorted elements bubbles up to its correct position, reducing the range of the next pass by one.\n",
    "5. Repeat the steps until no swaps are needed, indicating that the list is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubble sort: [11, 12, 22, 25, 34, 64, 90]\n"
     ]
    }
   ],
   "source": [
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        # Flag to detect any swap\n",
    "        swapped = False\n",
    "        # Last i elements are already in place\n",
    "        for j in range(0, n - i - 1):\n",
    "            # Swap if the element found is greater than the next element\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "                swapped = True\n",
    "        # If no two elements were swapped by inner loop, then break\n",
    "        if not swapped:\n",
    "            break\n",
    "    return arr\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [64, 34, 25, 12, 22, 11, 90]\n",
    "bubble_sort(arr)\n",
    "print(\"Bubble sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertion Sort <a id=\"insertion-sort\"></a>\n",
    "\n",
    "_Insertion Sort_ is a simple and intuitive sorting algorithm that builds the final sorted array (or list) one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort. However, its simplicity and the fact that it makes minimal number of swaps makes it efficient for small data sets and nearly sorted arrays. Moreover, it's stable, meaning that it maintains the relative order of equal elements.\n",
    "\n",
    "- **Time Complexity**:\n",
    "    - **Best-case time complexity**: _O(n)_, which occurs when the array is already sorted. In this case, the algorithm only needs to make one comparison per element.\n",
    "    - **Average and worst-case time complexity**: _O(n^2)_, due to the nested loops, where n is the number of items being sorted. The worst case occurs when the array is sorted in reverse order.\n",
    "- **Space complexity**: _O(1)_, because it only requires a fixed amount of extra storage space.\n",
    "\n",
    "_How Insertion Sort Works:_\n",
    "\n",
    "The algorithm divides the input list into two parts: the sublist of items already sorted (which is built up from left to right at the front of the list), and the sublist of items remaining to be sorted that occupy the rest of the list. Initially, the sorted sublist is just the first element of the list. The algorithm proceeds by removing one element from the remaining sublist and inserting it into the correct position within the sorted sublist, repeating until no elements remain in the unsorted sublist.\n",
    "\n",
    "Here are the steps for insertion sort:\n",
    "\n",
    "1. **Consider the first element to be sorted and the rest to be unsorted**.\n",
    "2. **Take the first element in the unsorted segment and scan backward into the sorted segment for the correct position to insert the element**.\n",
    "3. **Repeat step 2 for all elements in the unsorted segment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion sort: [5, 6, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "def insertion_sort(arr):\n",
    "    # Traverse through 1 to len(arr)\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        # Move elements of arr[0..i-1], that are greater than key, to one position ahead of their current position\n",
    "        j = i - 1\n",
    "        while j >= 0 and key < arr[j]:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "    return arr\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [12, 11, 13, 5, 6]\n",
    "insertion_sort(arr)\n",
    "print(\"Insertion sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection Sort <a id=\"selection-sort\"></a>\n",
    "\n",
    "_Selection Sort_ is a straightforward and intuitive sorting algorithm. The algorithm divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right.\n",
    "\n",
    "- **Time Complexity**:\n",
    "    - **Worst-case performance**: _O(n^2)_ comparisons and swaps, where _n_ is the number of elements in the array. This is because for each element in the array, you perform _n-1_ comparisons the first time, _n-2_ the next time, and so on.\n",
    "    - **Best-case performance**: _O(n^2)_ comparisons, but _O(1)_ swaps. The best-case time complexity is the same as the worst-case time complexity because even if the array is already sorted, you still need to compare each element to find the minimum.\n",
    "    - **Average performance**: _O(n^2)_ comparisons and swaps.\n",
    "- **Space complexity**: _O(1)_, because it only requires a constant amount of extra storage space for temporary variables, regardless of the size of the input array.\n",
    "\n",
    "_How Selection Sort Works:_\n",
    "\n",
    "1. **Start with the first element in the array** as the minimum (or maximum for descending order) value. This element is considered as part of the unsorted section of the array.\n",
    "2. **Scan the rest of the array** using a loop to find the minimum (or maximum) element in the unsorted section of the array.\n",
    "3. **After completing the scan**, swap the minimum (or maximum) found in the unsorted portion with the first element of the unsorted portion.\n",
    "4. **Move the boundary** of the unsorted portion one step to the right, effectively increasing the size of the sorted portion by one and decreasing the size of the unsorted portion by one.\n",
    "5. **Repeat the process** for each element in the array until the entire array is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection sort: [11, 12, 22, 25, 64]\n"
     ]
    }
   ],
   "source": [
    "def selection_sort(arr):\n",
    "    # Traverse through all array elements\n",
    "    for i in range(len(arr)):\n",
    "        # Find the minimum element in the remaining unsorted array\n",
    "        min_idx = i\n",
    "        for j in range(i + 1, len(arr)):\n",
    "            if arr[min_idx] > arr[j]:\n",
    "                min_idx = j\n",
    "        # Swap the found minimum element with the first element of the unsorted section\n",
    "        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n",
    "    return arr\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [64, 25, 12, 22, 11]\n",
    "selection_sort(arr)\n",
    "print(\"Selection sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Sort <a id=\"quick-sort\"></a>\n",
    "\n",
    "_Quick Sort_ is a highly efficient sorting algorithm and is based on the divide-and-conquer principle. It is able to sort large datasets significantly faster than similar algorithms, such as bubble sort, selection sort, and insertion sort, especially when the data is random. Quick Sort is also known as \"partition-exchange sort.\"\n",
    "\n",
    "- **Time Complexity**:\n",
    "   - **Best and Average Case**: The time complexity of Quick Sort is _O(n log n)_ in the best and average cases. These cases occur when the pivot element divides the list into two roughly equal halves, leading to a logarithmic number of levels of recursion.\n",
    "   - **Worst Case**: The worst-case time complexity of Quick Sort is _O(n^2)_. This scenario occurs when the pivot element is the smallest or largest element of the list, leading to one sub-array with _n-1_ elements and the other with _0_ elements, which results in quadratic performance. However, this worst-case scenario can be mitigated with good pivot selection strategies.\n",
    "- **Space Complexity**: _O(log n)_ in the best case due to the space used on the stack during recursion. In the worst case, it can grow to _O(n)_, depending on the implementation of the algorithm and the depth of the recursion stack.\n",
    "\n",
    "_How Quick Sort Works:_\n",
    "\n",
    "1. **Choose a \"pivot\" element** from the array. The choice of pivot can vary‚Äîcommon methods include choosing the first element, the last element, the median element, or a random element.\n",
    "\n",
    "2. **Partition the array** into two sub-arrays:\n",
    "   - Elements less than or equal to the pivot.\n",
    "   - Elements greater than the pivot.\n",
    "\n",
    "   The partitioning step rearranges the array so that all elements with values less than the pivot come before the pivot, while all elements with values greater than the pivot come after it. After this step, the pivot is in its final position.\n",
    "\n",
    "3. **Recursively apply the above steps** to the sub-array of elements with smaller values and the sub-array of elements with greater values.\n",
    "\n",
    "The recursion ends when the sub-array has fewer than two elements, meaning that the entire array becomes sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick sort: [1, 1, 2, 3, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Recursive implementation of the quick sort algorithm\n",
    "\n",
    "\n",
    "def quick_sort(arr):\n",
    "    # Base case: arrays with 0 or 1 element are already sorted\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "\n",
    "    # Recursive case\n",
    "    pivot = arr[len(arr) // 2]\n",
    "\n",
    "    left = [x for x in arr if x < pivot]  # All elements less than pivot\n",
    "    middle = [x for x in arr if x == pivot]  # All elements equal to pivot\n",
    "    right = [x for x in arr if x > pivot]  # All elements greater than pivot\n",
    "\n",
    "    return quick_sort(left) + middle + quick_sort(right)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [3, 6, 8, 10, 1, 2, 1]\n",
    "sorted_arr = quick_sort(arr)\n",
    "print(\"Quick sort:\", sorted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick sort in place: [1, 5, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# Quick sort in place (more efficient in terms of memory)\n",
    "\n",
    "\n",
    "def quick_sort(arr, low, high):\n",
    "    if low < high:\n",
    "        # pi is partitioning index, arr[pi] is now at right place\n",
    "        pi = partition(arr, low, high)\n",
    "\n",
    "        # Separately sort elements before partition and after partition\n",
    "        quick_sort(arr, low, pi - 1)\n",
    "        quick_sort(arr, pi + 1, high)\n",
    "\n",
    "\n",
    "def partition(arr, low, high):\n",
    "    pivot = arr[high]  # pivot\n",
    "    i = (\n",
    "        low - 1\n",
    "    )  # Index of smaller element and indicates the right position of pivot found so far\n",
    "\n",
    "    for j in range(low, high):\n",
    "        # If current element is smaller than the pivot\n",
    "        if arr[j] < pivot:\n",
    "            i = i + 1\n",
    "            arr[i], arr[j] = arr[j], arr[i]\n",
    "\n",
    "    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [10, 7, 8, 9, 1, 5]\n",
    "n = len(arr)\n",
    "quick_sort(arr, 0, n - 1)\n",
    "print(\"Quick sort in place:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Sort <a id=\"merge-sort\"></a>\n",
    "\n",
    "_Merge Sort_ is a divide-and-conquer algorithm that divides the input array into two halves, recursively sorts the two halves, and then merges the two sorted halves. The main advantage of Merge Sort is its consistent _O(n log n)_ performance for sorting, making it efficient for large datasets. It's also stable, which means it preserves the input order of equal elements in the sorted output, an important property for certain applications.\n",
    "\n",
    "- **Time Complexity**: _O(n log n)_, where _n_ is the number of elements in the array. This time complexity arises because the array is split into halves (which takes _log n_ splits), and each split requires merging an n-length list.\n",
    "- **Space Complexity**: _O(n)_, due to the temporary arrays used in the merge step.\n",
    "\n",
    "_How Merge Sort Works:_\n",
    "\n",
    "1. **Divide**: The array is divided into two halves (sub-arrays), and this process is repeated for each half until there are sub-arrays that can no longer be divided - essentially, when a sub-array has only one element.\n",
    "2. **Conquer**: Each pair of elements is then merged back together in a sorted order. This step is recursively applied, merging smaller sorted arrays into larger sorted arrays until the whole array is merged and sorted.\n",
    "3. **Merge**: The merging of two sorted arrays is accomplished through a merge function. This function compares the elements of the arrays and inserts the smaller element into the resulting array, continuing this process until all elements in the two arrays have been merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge sort: [5, 6, 7, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "def merge_sort(arr):\n",
    "    if len(arr) > 1:\n",
    "        mid = len(arr) // 2  # Finding the mid of the array\n",
    "        L = arr[:mid]  # Dividing the array elements into 2 halves\n",
    "        R = arr[mid:]\n",
    "\n",
    "        merge_sort(L)  # Sorting the first half\n",
    "        merge_sort(R)  # Sorting the second half\n",
    "\n",
    "        i = j = k = 0\n",
    "\n",
    "        # Copy data to temp arrays L[] and R[]\n",
    "        while i < len(L) and j < len(R):\n",
    "            if L[i] < R[j]:\n",
    "                arr[k] = L[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                arr[k] = R[j]\n",
    "                j += 1\n",
    "            k += 1\n",
    "\n",
    "        # Checking if any element was left\n",
    "        while i < len(L):\n",
    "            arr[k] = L[i]\n",
    "            i += 1\n",
    "            k += 1\n",
    "\n",
    "        while j < len(R):\n",
    "            arr[k] = R[j]\n",
    "            j += 1\n",
    "            k += 1\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [12, 11, 13, 5, 6, 7]\n",
    "merge_sort(arr)\n",
    "print(\"Merge sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heap Sort <a id=\"heap-sort\"></a>\n",
    "\n",
    "_Heap Sort_ is a comparison-based sorting algorithm that uses a binary heap data structure to create a sorted array. Unlike other sorting algorithms like bubble sort, selection sort, and insertion sort, heap sort has a better worst-case time complexity of _O(n log n)_. The key idea behind heap sort is to first transform the list into a max heap (or min heap, depending on the sorting order required), a complete binary tree where the largest (or smallest) element is at the root. The algorithm then repeatedly removes the largest (or smallest) element from the heap and rebuilds the heap, until all elements are removed from the heap and inserted into the array in sorted order.\n",
    "\n",
    "- **Time Complexity**: The time complexity of Heap Sort is _O(n log n)_ in all cases. This is because the initial build of the heap is _O(n)_, and each of the _n_ removals of the largest remaining element from the heap and subsequent heapify is _O(log n)_.\n",
    "- **Space Complexity**: _O(1)_, as Heap Sort sorts the array in place with only a constant amount of extra storage space.\n",
    "\n",
    "_How Heap Sort Works:_\n",
    "\n",
    "1. **Build a Max Heap (or Min Heap)** from the input data. In a Max Heap, the largest element is at the root. The heap is represented as an array, where for any given index i, its children are at indices 2i+1 and 2i+2.\n",
    "\n",
    "2. **Heapify**: The process of reshaping a binary tree into a Heap data structure. Each parent node is recursively checked and made sure that the parent node is larger (or smaller) than the child nodes.\n",
    "\n",
    "3. **Sort**:\n",
    "   - The root of the heap (the largest or smallest element) is swapped with the last element of the heap.\n",
    "   - Reduce the size of the heap by 1, effectively removing the last element from the heap.\n",
    "   - Heapify the root of the tree.\n",
    "   - Repeat the above steps until the heap size is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heap sort: [5, 6, 7, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "def heapify(arr, n, i):\n",
    "    largest = i  # Initialize largest as root\n",
    "    l = 2 * i + 1  # left = 2*i + 1\n",
    "    r = 2 * i + 2  # right = 2*i + 2\n",
    "\n",
    "    # See if left child of root exists and is greater than root\n",
    "    if l < n and arr[l] > arr[largest]:\n",
    "        largest = l\n",
    "\n",
    "    # See if right child of root exists and is greater than root\n",
    "    if r < n and arr[r] > arr[largest]:\n",
    "        largest = r\n",
    "\n",
    "    # Change root, if needed\n",
    "    if largest != i:\n",
    "        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n",
    "\n",
    "        # Heapify the root.\n",
    "        heapify(arr, n, largest)\n",
    "\n",
    "\n",
    "def heapSort(arr):\n",
    "    n = len(arr)\n",
    "\n",
    "    # Build a maxheap.\n",
    "    for i in range(n // 2 - 1, -1, -1):\n",
    "        heapify(arr, n, i)\n",
    "\n",
    "    # One by one extract elements\n",
    "    for i in range(n - 1, 0, -1):\n",
    "        arr[i], arr[0] = arr[0], arr[i]  # swap\n",
    "        heapify(arr, i, 0)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [12, 11, 13, 5, 6, 7]\n",
    "heapSort(arr)\n",
    "print(\"Heap sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Sort <a id=\"counting-sort\"></a>\n",
    "\n",
    "_Counting Sort_ is a non-comparison-based sorting algorithm that sorts the elements of an array by counting the number of occurrences of each unique element in the array. The algorithm then uses these counts to determine the position of each element in the output array. Counting Sort works best when the range of potential items in the input array (the difference between the maximum and minimum elements) is not significantly larger than the number of items. It is often used as a subroutine in more complex sorting algorithms, like Radix Sort, for sorting digits.\n",
    "\n",
    "- **Time Complexity**: The time complexity of Counting Sort is _O(n + k)_, where _n_ is the number of elements in the input array, and _k_ is the range of the input. The efficiency of Counting Sort depends heavily on the value of _k_ (the difference between the maximum and minimum elements in the array).\n",
    "- **Space Complexity**: _O(k)_, where _k_ is the range of the input. Additional space is required for the count array and the output array.\n",
    "\n",
    "_How Counting Sort Works:_\n",
    "\n",
    "1. **Find the Range**: Determine the minimum and maximum values in the input array.\n",
    "2. **Count Occurrences**: Create a count array to store the count of each unique value in the input array. The size of the count array is determined by the range of input values.\n",
    "3. **Cumulative Count**: Modify the count array by adding the sum of the previous counts. This step transforms the count array into a cumulative count array, which indicates the position of each element in the sorted array.\n",
    "4. **Place the Elements**: Iterate through the input array, place each element in its correct position in the output array using the cumulative count array, and decrease the count by one for each element processed.\n",
    "5. **Copy to Original Array** (optional): If sorting needs to be done in-place, the sorted elements from the output array can be copied back to the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting sort: [1, 2, 2, 3, 3, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "def counting_sort(arr):\n",
    "    # Find the maximum element in the array\n",
    "    max_val = max(arr)\n",
    "    min_val = min(arr)\n",
    "    range_of_elements = max_val - min_val + 1\n",
    "\n",
    "    # Create count array and initialize all elements to 0\n",
    "    count = [0] * range_of_elements\n",
    "    output = [0] * len(arr)\n",
    "\n",
    "    # Store the count of each element in count array\n",
    "    for i in range(0, len(arr)):\n",
    "        count[arr[i] - min_val] += 1\n",
    "\n",
    "    # Change count[i] so that count[i] contains the actual position\n",
    "    # of this element in the output array\n",
    "    for i in range(1, len(count)):\n",
    "        count[i] += count[i - 1]\n",
    "\n",
    "    # Build the output array\n",
    "    for i in range(len(arr) - 1, -1, -1):\n",
    "        output[count[arr[i] - min_val] - 1] = arr[i]\n",
    "        count[arr[i] - min_val] -= 1\n",
    "\n",
    "    # Copy the sorted elements into the original array\n",
    "    for i in range(0, len(arr)):\n",
    "        arr[i] = output[i]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [4, 2, 2, 8, 3, 3, 1]\n",
    "counting_sort(arr)\n",
    "print(\"Counting sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radix Sort <a id=\"radix-sort\"></a>\n",
    "\n",
    "_Radix Sort_ is a non-comparison-based sorting algorithm that sorts numbers by processing individual digits. Unlike other sorting algorithms that compare entire numbers to each other, Radix Sort processes the integers digit by digit, starting from the least significant digit (LSD) to the most significant digit (MSD), or vice versa, depending on the implementation. It uses counting sort (or sometimes other stable sort algorithms) as a subroutine to sort the elements based on each digit.\n",
    "\n",
    "Because it processes digits and not the whole numbers, Radix Sort has unique characteristics and performance considerations.\n",
    "\n",
    "- **Time Complexity**: The time complexity of Radix Sort is _O(d(n + k))_, where:\n",
    "  - _n_ is the number of elements,\n",
    "  - _k_ is the range of the input (the number of distinct digits or keys),\n",
    "  - _d_ is the number of digits in the longest number.\n",
    "\n",
    "  The efficiency of Radix Sort can be very good if the number of digits (_d_) is relatively small compared to the input size (_n_).\n",
    "\n",
    "- **Space Complexity**: _O(n + k)_, due to the storage needed for the counting process (in Counting Sort) and the queue or temporary array used for collecting digits.\n",
    "\n",
    "_How Radix Sort Works:_\n",
    "\n",
    "1. **Counting Sort by Digit**: Radix Sort works by performing multiple passes of Counting Sort, one for each digit. In each pass, it sorts the numbers based on the current digit being considered, starting from the least significant digit (LSD strategy) or the most significant digit (MSD strategy).\n",
    "   \n",
    "2. **Stable Sorting**: It's crucial that the sorting algorithm used for sorting digits is stable. A stable sort ensures that two items with the same value are ordered in the same sequence as they appear in the input. This property is essential for preserving the order of digits sorted in previous iterations as Radix Sort progresses through each digit.\n",
    "\n",
    "3. **Repeat for Each Digit**: After sorting by the least significant digit, the algorithm moves to the next digit and performs a sort on that digit, taking into account the stability of elements sorted in previous passes. This process repeats, moving through digits, until the most significant digit is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radix sort: [1, 23, 45, 121, 432, 564, 788]\n"
     ]
    }
   ],
   "source": [
    "def counting_sort_for_radix(input_list, place):\n",
    "    size = len(input_list)\n",
    "    output = [0] * size\n",
    "    count = [0] * 10\n",
    "\n",
    "    # Calculate count of elements\n",
    "    for i in range(size):\n",
    "        index = input_list[i] // place\n",
    "        count[index % 10] += 1\n",
    "\n",
    "    # Calculate cumulative count\n",
    "    for i in range(1, 10):\n",
    "        count[i] += count[i - 1]\n",
    "\n",
    "    # Place the elements in sorted order\n",
    "    i = size - 1\n",
    "    while i >= 0:\n",
    "        index = input_list[i] // place\n",
    "        output[count[index % 10] - 1] = input_list[i]\n",
    "        count[index % 10] -= 1\n",
    "        i -= 1\n",
    "\n",
    "    for i in range(size):\n",
    "        input_list[i] = output[i]\n",
    "\n",
    "\n",
    "def radix_sort(input_list):\n",
    "    # Find the maximum number to know the number of digits\n",
    "    max_num = max(input_list)\n",
    "    place = 1\n",
    "    # Apply counting sort to sort elements based on place value\n",
    "    while max_num // place > 0:\n",
    "        counting_sort_for_radix(input_list, place)\n",
    "        place *= 10\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [121, 432, 564, 23, 1, 45, 788]\n",
    "radix_sort(arr)\n",
    "print(\"Radix sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Sorting Algorithms Time Complexities <a id=\"common-sorting-algorithms-time-complexities\"></a>\n",
    "\n",
    "Here are the time complexities for common sorting algorithms:\n",
    "\n",
    "| Algorithm              | Best      | Average   | Worst     | Space     | Stable    | Notes |\n",
    "|------------------------|-----------|-----------|-----------|-----------|-----------|-------|\n",
    "| Bubble Sort            | O(n)      | O(n^2)    | O(n^2)    | O(1)      | Yes       |       |\n",
    "| Insertion Sort         | O(n)      | O(n^2)    | O(n^2)    | O(1)      | Yes       |       |\n",
    "| Selection Sort         | O(n^2)    | O(n^2)    | O(n^2)    | O(1)      | No        |       |\n",
    "| Quick Sort             | O(n log n)| O(n log n)| O(n^2)    | O(log n)  | No        | Quicksort is usually done in place with O(log n) stack space. |\n",
    "| Merge Sort             | O(n log n)| O(n log n)| O(n log n)| O(n)      | Yes       |       |\n",
    "| Heap Sort              | O(n log n)| O(n log n)| O(n log n)| O(1)      | No        |       |\n",
    "| Counting Sort          | O(n + k)  | O(n + k)  | O(n + k)  | O(n + k)  | Yes       | k is the range of the non-negative key values. |\n",
    "| Radix Sort             | O(nk)     | O(nk)     | O(nk)     | O(n + k)  | Yes       | k is the number of passes of the sort. |\n",
    "\n",
    "Stability: A sorting algorithm is said to be stable if two objects with equal keys appear in the same order in sorted output as they appear in the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Searching Algorithms <a id=\"searching-algorithms\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear <a id=\"linear\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary <a id=\"binary\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Graph Algorithms <a id=\"graph-algorithms\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth-First Search <a id=\"depth-first-search\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breadth-First Search <a id=\"breadth-first-search\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dijkstra's <a id=\"dijkstras\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bellman-Ford <a id=\"bellman-ford\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Problem Solving Methods <a id=\"problem-solving-methods\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Pointers <a id=\"two-pointers\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide and Conquer <a id=\"divide-and-conquer\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursion <a id=\"recursion\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Programming <a id=\"dynamic-programming\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Algorithms <a id=\"greedy-algorithms\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
