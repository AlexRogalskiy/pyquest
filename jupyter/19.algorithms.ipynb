{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part XIX: Algorithms <a id=\"19-algorithms\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Time Complexity and Big O Notation <a id=\"time-complexity-and-big-o-notation\"></a>\n",
    "\n",
    "_Time complexity_ and _Big O_ notation are foundational concepts in computer science, particularly in the analysis of algorithms. They are used to describe the performance of algorithms and the amount of time they take to run as a function of the size of their input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Complexity <a id=\"time-complexity\"></a>\n",
    "\n",
    "_Time complexity_ is a measure of the amount of computational time that an algorithm takes to complete as a function of the length of the input. It gives us an idea of the growth rate of the runtime of an algorithm as the size of input data increases. Time complexity is important because it helps us to predict the scalability of an algorithm and to determine whether it is practical for large datasets.\n",
    "\n",
    "There are several types of time complexity measures, including:\n",
    "\n",
    "- **Worst-case time complexity (Big O notation)**: The maximum amount of time an algorithm could take to complete, regardless of the input size.\n",
    "- **Average-case time complexity (ùõÄ omega notation)**: The expected amount of time an algorithm will take to complete, over all possible inputs of a given size.\n",
    "- **Best-case time complexity (ùöØ theta notation)**: The minimum amount of time an algorithm could take to complete, which usually occurs under ideal conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big O Notation <a id=\"big-o-notation\"></a>\n",
    "\n",
    "_Big O_ notation is a mathematical notation used to describe the upper bound of the time complexity of an algorithm. It expresses the worst-case scenario of an algorithm's growth rate, allowing us to compare the efficiency of different algorithms regardless of hardware or software differences. Big O notation focuses on the main factor that affects the growth rate, ignoring constants and smaller terms, which become negligible as the input size grows.\n",
    "\n",
    "Here are some common Big O notations and their meanings:\n",
    "\n",
    "- **O(1)**: Constant time - The execution time of the algorithm does not change with the size of the input data set.\n",
    "- **O(log n)**: Logarithmic time - The execution time of the algorithm increases logarithmically as the input data set size increases.\n",
    "- **O(n)**: Linear time - The execution time increases linearly with the increase in input data set size.\n",
    "- **O(n log n)**: Linearithmic time - The execution time increases linearly and logarithmically with the increase in input data set size. Many efficient sorting algorithms have this time complexity.\n",
    "- **O(n^2)**: Quadratic time - The execution time increases quadratically with the increase in input data set size. This is common in algorithms that involve nested iterations over the data set.\n",
    "- **O(2^n)**: Exponential time - The execution time doubles with each addition to the input data set size. This is often seen in algorithms that generate all subsets of a set.\n",
    "- **O(n!)**: Factorial time - The execution time grows factorially with the increase in input data set size. This is typical in algorithms that generate all permutations of a set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Data Structure Time Complexities <a id=\"common-data-structure-time-complexities\"></a>\n",
    "\n",
    "Here are the time complexities for common data structures:\n",
    "\n",
    "| Data Structure         | Access    | Search    | Insertion | Deletion  | Remarks                      |\n",
    "|------------------------|-----------|-----------|-----------|-----------|------------------------------|\n",
    "| Array (Dynamic)        | O(1)      | O(n)      | O(n)      | O(n)      | Worst case for insertion/deletion due to resizing and copying. |\n",
    "| Array (Fixed Size)     | O(1)      | O(n)      | N/A       | N/A       | Size is fixed; cannot insert or delete. |\n",
    "| Singly Linked List     | O(n)      | O(n)      | O(1)      | O(1)      | Assuming insertion/deletion at the head. |\n",
    "| Doubly Linked List     | O(n)      | O(n)      | O(1)      | O(1)      | Assuming insertion/deletion at the head/tail. |\n",
    "| Stack                  | O(n)      | O(n)      | O(1)      | O(1)      | Access is O(n) since you need to pop n-1 elements to access the nth. |\n",
    "| Queue                  | O(n)      | O(n)      | O(1)      | O(1)      | Enqueue is O(1), dequeue is O(1); accessing arbitrary elements is O(n). |\n",
    "| Deque (Double-Ended Queue) | O(n)   | O(n)      | O(1)      | O(1)      | Insertion and deletion are O(1) at both ends. |\n",
    "| Hash Table (Unsorted)  | N/A       | O(1)      | O(1)      | O(1)      | Average case; worst-case is O(n) if a collision occurs. |\n",
    "| Binary Search Tree     | O(log n)  | O(log n)  | O(log n)  | O(log n)  | Average case for balanced tree; worst-case is O(n) if unbalanced. |\n",
    "| Balanced Tree (AVL, Red-Black Tree) | O(log n) | O(log n) | O(log n)  | O(log n)  | Maintains balance to ensure O(log n) operations. |\n",
    "| Heap (Binary)          | O(1)      | O(n)      | O(log n)  | O(log n)  | Min/Max value is O(1); finding arbitrary values is O(n). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sorting Algorithms <a id=\"sorting-algorithms\"></a>\n",
    "\n",
    "_Sorting algorithms_ are used to rearrange a list of elements into a particular order, such as numerical, lexicographical, or some other order. Sorting is a fundamental operation in computer science and is used in a wide variety of applications, including searching, data analysis, and database operations.\n",
    "\n",
    "There are many different sorting algorithms, each with its own advantages and disadvantages. The choice of sorting algorithm depends on the size of the data set, the nature of the data, and the available resources. Here are some common sorting algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bubble <a id=\"bubble\"></a>\n",
    "\n",
    "_Bubble Sort_ is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted. The algorithm is named for the way smaller elements \"bubble\" to the top of the list (beginning of the list) because, during each pass, the largest unsorted element bubbles up to its correct position.\n",
    "\n",
    "- **Time Complexity**:\n",
    "  - **Best Case**: _O(n)_ when the array is already sorted, and the algorithm makes a pass to check.\n",
    "  - **Average Case**: _O(n^2)_ for unsorted or partially sorted arrays.\n",
    "  - **Worst Case**: _O(n^2)_ when the array is sorted in reverse order.\n",
    "- **Space Complexity**: _O(1)_ since it only uses a constant amount of extra space for swapping.\n",
    "\n",
    "_How Bubble Sort Works:_\n",
    "\n",
    "1. **Starting from the first index**, compare the current element with the next element.\n",
    "2. **Swap** if the current element is greater than the next element.\n",
    "3. **Move to the next element** and repeat the process until the end of the array.\n",
    "4. After each pass, the largest element among the unsorted elements bubbles up to its correct position, reducing the range of the next pass by one.\n",
    "5. Repeat the steps until no swaps are needed, indicating that the list is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubble sort: [11, 12, 22, 25, 34, 64, 90]\n"
     ]
    }
   ],
   "source": [
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        # Flag to detect any swap\n",
    "        swapped = False\n",
    "        # Last i elements are already in place\n",
    "        for j in range(0, n - i - 1):\n",
    "            # Swap if the element found is greater than the next element\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "                swapped = True\n",
    "        # If no two elements were swapped by inner loop, then break\n",
    "        if not swapped:\n",
    "            break\n",
    "    return arr\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [64, 34, 25, 12, 22, 11, 90]\n",
    "bubble_sort(arr)\n",
    "print(\"Bubble sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertion <a id=\"insertion\"></a>\n",
    "\n",
    "_Insertion Sort_ is a simple and intuitive sorting algorithm that builds the final sorted array (or list) one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort. However, its simplicity and the fact that it makes minimal number of swaps makes it efficient for small data sets and nearly sorted arrays. Moreover, it's stable, meaning that it maintains the relative order of equal elements.\n",
    "\n",
    "- **Time Complexity**:\n",
    "    - **Best-case time complexity**: _O(n)_, which occurs when the array is already sorted. In this case, the algorithm only needs to make one comparison per element.\n",
    "    - **Average and worst-case time complexity**: _O(n^2)_, due to the nested loops, where n is the number of items being sorted. The worst case occurs when the array is sorted in reverse order.\n",
    "- **Space complexity**: _O(1)_, because it only requires a fixed amount of extra storage space.\n",
    "\n",
    "_How Insertion Sort Works:_\n",
    "\n",
    "The algorithm divides the input list into two parts: the sublist of items already sorted (which is built up from left to right at the front of the list), and the sublist of items remaining to be sorted that occupy the rest of the list. Initially, the sorted sublist is just the first element of the list. The algorithm proceeds by removing one element from the remaining sublist and inserting it into the correct position within the sorted sublist, repeating until no elements remain in the unsorted sublist.\n",
    "\n",
    "Here are the steps for insertion sort:\n",
    "\n",
    "1. **Consider the first element to be sorted and the rest to be unsorted**.\n",
    "2. **Take the first element in the unsorted segment and scan backward into the sorted segment for the correct position to insert the element**.\n",
    "3. **Repeat step 2 for all elements in the unsorted segment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion sort: [5, 6, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "def insertion_sort(arr):\n",
    "    # Traverse through 1 to len(arr)\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        # Move elements of arr[0..i-1], that are greater than key, to one position ahead of their current position\n",
    "        j = i - 1\n",
    "        while j >= 0 and key < arr[j]:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "    return arr\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [12, 11, 13, 5, 6]\n",
    "insertion_sort(arr)\n",
    "print(\"Insertion sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection <a id=\"selection\"></a>\n",
    "\n",
    "_Selection Sort_ is a straightforward and intuitive sorting algorithm. The algorithm divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right.\n",
    "\n",
    "- **Time Complexity**:\n",
    "    - **Worst-case performance**: _O(n^2)_ comparisons and swaps, where _n_ is the number of elements in the array. This is because for each element in the array, you perform _n-1_ comparisons the first time, _n-2_ the next time, and so on.\n",
    "    - **Best-case performance**: _O(n^2)_ comparisons, but _O(1)_ swaps. The best-case time complexity is the same as the worst-case time complexity because even if the array is already sorted, you still need to compare each element to find the minimum.\n",
    "    - **Average performance**: _O(n^2)_ comparisons and swaps.\n",
    "- **Space complexity**: _O(1)_, because it only requires a constant amount of extra storage space for temporary variables, regardless of the size of the input array.\n",
    "\n",
    "_How Selection Sort Works:_\n",
    "\n",
    "1. **Start with the first element in the array** as the minimum (or maximum for descending order) value. This element is considered as part of the unsorted section of the array.\n",
    "2. **Scan the rest of the array** using a loop to find the minimum (or maximum) element in the unsorted section of the array.\n",
    "3. **After completing the scan**, swap the minimum (or maximum) found in the unsorted portion with the first element of the unsorted portion.\n",
    "4. **Move the boundary** of the unsorted portion one step to the right, effectively increasing the size of the sorted portion by one and decreasing the size of the unsorted portion by one.\n",
    "5. **Repeat the process** for each element in the array until the entire array is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection sort: [11, 12, 22, 25, 64]\n"
     ]
    }
   ],
   "source": [
    "def selection_sort(arr):\n",
    "    # Traverse through all array elements\n",
    "    for i in range(len(arr)):\n",
    "        # Find the minimum element in the remaining unsorted array\n",
    "        min_idx = i\n",
    "        for j in range(i + 1, len(arr)):\n",
    "            if arr[min_idx] > arr[j]:\n",
    "                min_idx = j\n",
    "        # Swap the found minimum element with the first element of the unsorted section\n",
    "        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n",
    "    return arr\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [64, 25, 12, 22, 11]\n",
    "selection_sort(arr)\n",
    "print(\"Selection sort:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick <a id=\"quick\"></a>\n",
    "\n",
    "_Quick Sort_ is a highly efficient sorting algorithm and is based on the divide-and-conquer principle. It is able to sort large datasets significantly faster than similar algorithms, such as bubble sort, selection sort, and insertion sort, especially when the data is random. Quick Sort is also known as \"partition-exchange sort.\"\n",
    "\n",
    "- **Time Complexity**:\n",
    "   - **Best and Average Case**: The time complexity of Quick Sort is _O(n log n)_ in the best and average cases. These cases occur when the pivot element divides the list into two roughly equal halves, leading to a logarithmic number of levels of recursion.\n",
    "   - **Worst Case**: The worst-case time complexity of Quick Sort is _O(n^2)_. This scenario occurs when the pivot element is the smallest or largest element of the list, leading to one sub-array with _n-1_ elements and the other with _0_ elements, which results in quadratic performance. However, this worst-case scenario can be mitigated with good pivot selection strategies.\n",
    "- **Space Complexity**: _O(log n)_ in the best case due to the space used on the stack during recursion. In the worst case, it can grow to _O(n)_, depending on the implementation of the algorithm and the depth of the recursion stack.\n",
    "\n",
    "_How Quick Sort Works:_\n",
    "\n",
    "1. **Choose a \"pivot\" element** from the array. The choice of pivot can vary‚Äîcommon methods include choosing the first element, the last element, the median element, or a random element.\n",
    "\n",
    "2. **Partition the array** into two sub-arrays:\n",
    "   - Elements less than or equal to the pivot.\n",
    "   - Elements greater than the pivot.\n",
    "\n",
    "   The partitioning step rearranges the array so that all elements with values less than the pivot come before the pivot, while all elements with values greater than the pivot come after it. After this step, the pivot is in its final position.\n",
    "\n",
    "3. **Recursively apply the above steps** to the sub-array of elements with smaller values and the sub-array of elements with greater values.\n",
    "\n",
    "The recursion ends when the sub-array has fewer than two elements, meaning that the entire array becomes sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick sort: [1, 1, 2, 3, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Recursive implementation of the quick sort algorithm\n",
    "\n",
    "\n",
    "def quick_sort(arr):\n",
    "    # Base case: arrays with 0 or 1 element are already sorted\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "\n",
    "    # Recursive case\n",
    "    pivot = arr[len(arr) // 2]\n",
    "\n",
    "    left = [x for x in arr if x < pivot]  # All elements less than pivot\n",
    "    middle = [x for x in arr if x == pivot]  # All elements equal to pivot\n",
    "    right = [x for x in arr if x > pivot]  # All elements greater than pivot\n",
    "\n",
    "    return quick_sort(left) + middle + quick_sort(right)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [3, 6, 8, 10, 1, 2, 1]\n",
    "sorted_arr = quick_sort(arr)\n",
    "print(\"Quick sort:\", sorted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick sort in place: [1, 5, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# Quick sort in place (more efficient in terms of memory)\n",
    "\n",
    "\n",
    "def quick_sort(arr, low, high):\n",
    "    if low < high:\n",
    "        # pi is partitioning index, arr[pi] is now at right place\n",
    "        pi = partition(arr, low, high)\n",
    "\n",
    "        # Separately sort elements before partition and after partition\n",
    "        quick_sort(arr, low, pi - 1)\n",
    "        quick_sort(arr, pi + 1, high)\n",
    "\n",
    "\n",
    "def partition(arr, low, high):\n",
    "    pivot = arr[high]  # pivot\n",
    "    i = (\n",
    "        low - 1\n",
    "    )  # Index of smaller element and indicates the right position of pivot found so far\n",
    "\n",
    "    for j in range(low, high):\n",
    "        # If current element is smaller than the pivot\n",
    "        if arr[j] < pivot:\n",
    "            i = i + 1\n",
    "            arr[i], arr[j] = arr[j], arr[i]\n",
    "\n",
    "    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "# Example usage\n",
    "arr = [10, 7, 8, 9, 1, 5]\n",
    "n = len(arr)\n",
    "quick_sort(arr, 0, n - 1)\n",
    "print(\"Quick sort in place:\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge <a id=\"merge\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heap <a id=\"heap\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting <a id=\"counting\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radix <a id=\"radix\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Sorting Algorithms Time Complexities <a id=\"common-sorting-algorithms-time-complexities\"></a>\n",
    "\n",
    "Here are the time complexities for common sorting algorithms:\n",
    "\n",
    "| Algorithm              | Best      | Average   | Worst     | Space     | Stable    | Notes |\n",
    "|------------------------|-----------|-----------|-----------|-----------|-----------|-------|\n",
    "| Bubble Sort            | O(n)      | O(n^2)    | O(n^2)    | O(1)      | Yes       |       |\n",
    "| Insertion Sort         | O(n)      | O(n^2)    | O(n^2)    | O(1)      | Yes       |       |\n",
    "| Selection Sort         | O(n^2)    | O(n^2)    | O(n^2)    | O(1)      | No        |       |\n",
    "| Quick Sort             | O(n log n)| O(n log n)| O(n^2)    | O(log n)  | No        | Quicksort is usually done in place with O(log n) stack space. |\n",
    "| Merge Sort             | O(n log n)| O(n log n)| O(n log n)| O(n)      | Yes       |       |\n",
    "| Heap Sort              | O(n log n)| O(n log n)| O(n log n)| O(1)      | No        |       |\n",
    "| Counting Sort          | O(n + k)  | O(n + k)  | O(n + k)  | O(n + k)  | Yes       | k is the range of the non-negative key values. |\n",
    "| Radix Sort             | O(nk)     | O(nk)     | O(nk)     | O(n + k)  | Yes       | k is the number of passes of the sort. |\n",
    "\n",
    "Stability: A sorting algorithm is said to be stable if two objects with equal keys appear in the same order in sorted output as they appear in the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Searching Algorithms <a id=\"searching-algorithms\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear <a id=\"linear\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary <a id=\"binary\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Graph Algorithms <a id=\"graph-algorithms\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth-First Search <a id=\"depth-first-search\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breadth-First Search <a id=\"breadth-first-search\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dijkstra's <a id=\"dijkstras\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bellman-Ford <a id=\"bellman-ford\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Problem Solving Methods <a id=\"problem-solving-methods\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Pointers <a id=\"two-pointers\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide and Conquer <a id=\"divide-and-conquer\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursion <a id=\"recursion\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Programming <a id=\"dynamic-programming\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Algorithms <a id=\"greedy-algorithms\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
